<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dachuan Shi</title>
  
  <meta name="author" content="Dachuan Shi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
  <link rel="icon" type="image/png" href="images/thu.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dachuan Shi</name>
              </p>
              <p>I am a second-year master's student in <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, 
                where I am advised by <a href="https://www.sigs.tsinghua.edu.cn/yc2_en/main.htm">Prof. Chun Yuan</a>.  
                Previously, I received my B.Eng. in Computer Science and Technology also from <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, 
                advised by <a href="https://www.cs.tsinghua.edu.cn/csen/info/1208/4101.htm">Prof. Linmin Tao</a> . 
                I also work with <a href="https://myownskyw7.github.io/">Dr. Jiaqi Wang</a> at <a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a>.
              </p>
              <p>
                My research focuses on the combination of efficient deep learning and foundation models (multimodality, vision, and LLM). 
                Over the past year, I have worked on compression & acceleration frameworks for efficient vison-language and unimodal Transformers.
                Prior to that, I built efficient and lightweight structures for medical image analysis.
              </p>
              <p>
                Feel free to contact me at <a href="mailto:shidachuan17@gmail.com">shidachuan17@gmail.com</a> for collaboration or discussing new ideas.
              </p>
              <p style="text-align:center">
                <a href="mailto:shidachuan17@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/DachuanShi-CV.pdf">Curriculum Vitae</a> &nbsp/&nbsp
                <a href="https://www.dachuanshi.com">Homepage</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=ejECvlYAAAAJ&hl=en">Google Scholar</a>
                <!-- <a href="">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/DachuanShi_circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/DachuanShi_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications and Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				

        
      <tr>
        <td style="padding:20px;width:30%;vertical-align:middle">
          <img src="images/crossget.png" alt="crossget" width=110% height=100% style="border-style: none">
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2305.17455.pdf" id="crossget">
            <papertitle>CrossGET: Cross-Guided Ensemble of Tokens for Accelerating Vision-Language Transformers</papertitle>
          </a>
          [Efficient Deep Learning, Multimodal Learning]
          <br>
          <strong>Dachuan Shi</strong>, Chaofan Tao, Anyi Rao, Zhendong Yang, Chun Yuan, Jiaqi Wang
          <br>
          <em>In submission</em>, 2023
          <br>
          <a href="https://arxiv.org/pdf/2305.17455.pdf">Paper</a> / <a href="data/crossget.bib">Bibtex</a>
          <p> TL;DR: Propose a universal token ensemble framework CrossGET for accelerating various vision-language Transformers.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:30%;vertical-align:middle">
          <img src="images/upop.png" alt="upop" width=110% height=100% style="border-style: none">
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2301.13741.pdf" id="upop">
            <papertitle>UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers</papertitle>
          </a>
          [Efficient Deep Learning, Multimodal Learning]
          <br>
          <strong>Dachuan Shi</strong>, Chaofan Tao, Ying Jin, Zhendong Yang, Chun Yuan, Jiaqi Wang
          <br>
          <em>ICML</em>, 2023
          <br>
          <a href="https://arxiv.org/pdf/2301.13741.pdf">Paper</a> / <a href="data/upop.bib">Bibtex</a>
          <p> TL;DR: Propose a universal structured pruning framework UPop for compressing various vision-language and unimodal Transformers.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:30%;vertical-align:middle">
          <img src="images/heuristicDropout.png" alt="heuristicDropout" width=110% height=100% style="border-style: none">
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/abstract/document/9747409" id="heuristicDropout">
            <papertitle>Heuristic Dropout: An Efficient Regularization Method for Medical Image Segmentation Models</papertitle>
          </a>
          [Efficient Deep Learning, Medical Image Analysis]
          <br>
          <strong>Dachuan Shi</strong>, Ruiyang Liu, Linmi Tao, Chun Yuan
          <br>
          <em>ICASSP</em>, 2022
          <br>
          <a href="https://ieeexplore.ieee.org/abstract/document/9747409">Paper</a> / <a href="data/heuristicDropout.bib">Bibtex</a>
          <p> TL;DR: Propose Heuristic Dropout to more efficiently drop features suffering from the co-adaptation problem for medical image segmentation tasks.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:30%;vertical-align:middle">
          <img src="images/mepdnet.png" alt="mepdnet" width=110% height=100% style="border-style: none">
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/abstract/document/9506463" id="mepdnet">
            <papertitle>Multi-Encoder Parse-Decoder Network for Sequential Medical Image Segmentation </papertitle>
          </a>
          [Efficient Deep Learning, Medical Image Analysis]
          <br>
          <strong>Dachuan Shi</strong>, Ruiyang Liu, Linmi Tao, Chun Yuan
          <br>
          <em>ICIP</em>, 2021
          <br>
          <a href="https://ieeexplore.ieee.org/abstract/document/9506463">Paper</a> / <a href="data/mepdnet.bib">Bibtex</a>
          <p> TL;DR: Propose MEPDNet that comprises efficient parameter-shared encoders and a lightweight decoder for sequential medical image segmentation. </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:30%;vertical-align:middle">
          <img src="images/mgd.png" alt="mgd" width=110% height=100% style="border-style: none">
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2205.01529.pdf" id="mgd">
            <papertitle>Masked Generative Distillation </papertitle>
          </a>
          [Efficient Deep Learning, Computer Vision]
          <br>
          Zhendong Yang, Zhe Li, Mingqi Shao, <strong>Dachuan Shi</strong>, Zehuan Yuan, Chun Yuan
          <br>
          <em>ECCV</em>, 2022
          <br>
          <a href="https://arxiv.org/pdf/2205.01529.pdf">Paper</a> / <a href="data/mgd.bib">Bibtex</a>
          <p> TL;DR: Propose a generative distillation method MGD that randomly masks pixels of the student's feature and forces it to generate the teacher's full feature.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:30%;vertical-align:middle">
          <img src="images/pteacher.png" alt="pteacher" width=110% height=100% style="border-style: none">
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="https://arxiv.org/pdf/2105.05182.pdf" id="pteacher">
            <papertitle>PTeacher: a ComputerAided Personalized Pronunciation Training System with Exaggerated Audio-Visual Corrective Feedback</papertitle>
          </a>
          [Human-Computer Interaction, Multimodal Learning]
          <br>
          Yaohua Bu, Tianyi Ma, Weijun Li, Hang Zhou, Jia Jia, Shengqi Chen, Kaiyuan Xu, <strong>Dachuan Shi</strong>, Haozhe Wu, Zhihan Yang, Kun Li, Zhiyong Wu, Yuanchun Shi, Xiaobo Lu, Ziwei Liu
          <br>
          <em>CHI</em>, 2021
          <br>
          <a href="https://arxiv.org/pdf/2105.05182.pdf">Paper</a> / <a href="data/pteacher.bib">Bibtex</a>
          <p> TL;DR: Propose PTeacher as a pronunciation training system that provides personalized exaggerated audio-visual corrective feedback for mispronunciations.</p>
        </td>
      </tr>

      </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"><tbody>
          <tr>
            <td>
              <heading>Academic Services</heading>
            </td>
          </tr>
          <tr>
            <td width="70%" valign="center">
              Reviewer of NeurIPS 2023 and ECCV 2022.
            </td>
          </tr>
        </tbody></table>
        <br>

				<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:10px;width:100%;vertical-align:middle">
            <heading>Awards</heading>
            <ul>
              <li> Tsinghua Comprehensive Excellence Scholarship </li>
              <li> Tsinghua Outstanding Bachelor Thesis </li>
              <li> Tsinghua John Ma Cup Taekwondo Competition, 2nd place </li>
              <li> Beijing Capital University Taekwondo Elite Tournament, 5th place </li>
              <li> Chinese University Physics Competition in Selected Regions, 3rd Prize</li>

            </ul> 
          </td>
        </tr>
      </tbody></table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="10"><tbody>
        <tr>
          <td>
            <heading>Miscellaneous</heading>
          </td>
        </tr>
        <tr>
          <td width="70%" valign="center">
            I am a black belt in Taekwondo and used to be a member of the Taekwondo Athletic Team at Tsinghua University during my undergraduate. 
          </td>
        </tr>
      </tbody></table>
      <br>

      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=tt&d=AmqFkezJkoabjC618anINucZVgzGN8iOOciOp6_2d6A&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tr>
          <td style="padding:10px">
            <p style="text-align:right;font-size:small;">
               The template was modified from <a href="https://jonbarron.info/">Jon Barron</a>.
               <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=AmqFkezJkoabjC618anINucZVgzGN8iOOciOp6_2d6A&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff"></script>
            </p>
          </td>
        </tr>
      </table>
    </td>
    </tr>
  </table>
</body>

</html>
